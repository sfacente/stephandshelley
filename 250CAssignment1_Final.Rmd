---
title: "HW 1"
author: "Steph Holm and Shelley Facente"
date: "February 7, 2019"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = FALSE, cache = TRUE)

library(geepack)
library(doBy)
library(stats4) 
library(blm)

load("C:/Users/shell/Dropbox/_GRAD SCHOOL_/250C/frmgham_recoded.wide.Rdata")
```


```{r}
# First, (using provided code) we calculate the proportion of the sample who experienced the event:
hypertenprev <- table(frmgham_recoded.wide$hyperten)/sum(table(frmgham_recoded.wide$hyperten))

```


```{r}
# Then (using provided code) we estimate a logistic regression for the association of BMI on incident hypertension, adjusted for current smoking (binary), age (continuous), sex (binary), education (4-level):
frmgham_recoded.wide$bmi_cat <-relevel(as.factor(frmgham_recoded.wide$bmi_cat),"2")# Estimate logistic regression:
logistic.frmgham<-glm(hyperten~factor(bmi_cat)+cursmoke+age+factor(sex)+factor(educ),data=frmgham_recoded.wide,family=binomial)
summary(logistic.frmgham)
coef.logistic <-coef(logistic.frmgham)
ci.logistic <-confint.default(logistic.frmgham)
LogisticORs <- round(exp(cbind(coef.logistic, ci.logistic))[2:4,],2) #named this so we can call them later.

rm(ci.logistic)

```


```{r}
#Next we adapt the above code to estimate a log-binomial model for the BMI-hypertension association.
#I used lecture 2, slide 29 to do this

# 
# logbin.frmgham <-glm(hyperten~factor(bmi_cat)+cursmoke+age+factor(sex)+factor(educ),
#                      data=frmgham_recoded.wide,
#                      start = as.vector(coef.logistic), #giving it starting values because it doesn't converge without, used the values from the logistic
#                      family=binomial("log"))
# summary(logbin.frmgham)
# coef.logbin <-coef(logbin.frmgham)
# ci.logbin <-confint.default(logbin.frmgham)
# round(exp(cbind(coef.logbin, ci.logbin))[2:4,],2)

#gives an error saying 'cannot find valid starting values: please specify some'
#Helen notes that if the model is unable to converge, we can simply report that as our outcome, so I'm moving on.

#commented out this whole chunk since the model failed.


```


```{r}
# Next we adapt the above code to estimate a "modified Poisson" model for the BMI-hypertension association (hint: use the geeglm function as discussed in class) 
#I'm using lecture 2, slide 44 to do this and then lines 83-89 of his example code for the confidence intervals
frmgham_recoded.wide<- na.omit(frmgham_recoded.wide) #turns out there's no NAs, but thought I'd check

poisson.frmgham <-geeglm(hyperten~factor(bmi_cat)+cursmoke+age+factor(sex)+factor(educ)+ randid,
                     data=frmgham_recoded.wide, id = randid,
                     family=poisson(link="log"), corstr="exchangeable")
summary(poisson.frmgham)

fram.RR.coefci <- esticon(poisson.frmgham, diag(length(coef(poisson.frmgham))))
fram.RR.expci <- exp(cbind(fram.RR.coefci$Estimate, fram.RR.coefci$Lower, fram.RR.coefci$Upper))
rownames(fram.RR.expci) <- names(coef(poisson.frmgham))
colnames(fram.RR.expci) <- c("RR", "95% LL", "95% UL")
fram.RR.expci # RR from Poisson model

PoissonRR <- round(fram.RR.expci[2:4,],2) # This picks off the 2-4th rows (all columns) to focus on RRs for BMI

poissoncoef <- fram.RR.coefci[1:10,2]

rm(fram.RR.expci)
```


```{r}
#(using provided code) Create two new versions of the dataset representing two hypothetical populations: one where every individual is obese (bmi_cat=4), and one where every individual is ideal weight (bmi_cat=2); refer to them as frmgham_recoded.wide.obese and frmgham_recoded.wide.ideal, respectively:
# Create copies of the original dataset:
frmgham_recoded.wide.obese <-frmgham_recoded.wide.ideal <-frmgham_recoded.wide    # Set BMI to obese (in p1) and ideal weight (in p0):
frmgham_recoded.wide.obese$bmi_cat <-4
# Framingham population w/ all obese
frmgham_recoded.wide.ideal$bmi_cat <-2
# Framingham population w/ all ideal weight

# Obtain predicted individual risk of hypertension under each new dataset:
rhat.obese.logistic <-predict(logistic.frmgham,type="response",newdata=frmgham_recoded.wide.obese)

rhat.ideal.logistic <-predict(logistic.frmgham,type="response",newdata=frmgham_recoded.wide.ideal)
# Calculate the average risk of hypertension in each hypothetical population:
mu.rhat.obese.logistic <-mean(rhat.obese.logistic)
mu.rhat.ideal.logistic <-mean(rhat.ideal.logistic)
```


```{r}
#Use the quantities calculated above to estimate the risk ratio and risk difference comparing these two hypothetical populations.

Counterfactual.RR.logistic <- mu.rhat.obese.logistic/mu.rhat.ideal.logistic
Counterfactual.RD.logistic <- mu.rhat.obese.logistic-mu.rhat.ideal.logistic
```


```{r}
#Redo this exercise using the estimates from the modified Poisson model.
# Obtain predicted individual risk of hypertension under each new dataset:
rhat.obese.poisson <-predict(poisson.frmgham,type="response",newdata=frmgham_recoded.wide.obese)

rhat.ideal.poisson<-predict(poisson.frmgham,type="response",newdata=frmgham_recoded.wide.ideal)

# Calculate the average risk of hypertension in each hypothetical population:
mu.rhat.obese.poisson <-mean(rhat.obese.poisson)
mu.rhat.ideal.poisson <-mean(rhat.ideal.poisson)

Counterfactual.RR.poisson <- mu.rhat.obese.poisson/mu.rhat.ideal.poisson
Counterfactual.RD.poisson <- mu.rhat.obese.poisson-mu.rhat.ideal.poisson
```


```{r}
#Using the provided code, calculate using prior scenario one:
# Bring some variables into the global workspace:
attach(frmgham_recoded.wide)
hyperten <-hyperten
bmi1 <-as.integer(bmi_cat==1)
bmi2 <-as.integer(bmi_cat==2)
bmi3 <-as.integer(bmi_cat==3)
bmi4 <-as.integer(bmi_cat==4)

cursmoke <-cursmoke
age<-age
educ1 <-as.integer(educ==1)
educ2 <-as.integer(educ==2)
educ3 <-as.integer(educ==3)
educ4 <-as.integer(educ==4)

female <-as.integer(sex==2)
detach(frmgham_recoded.wide)

nLL <-function(beta1, beta2, beta3, beta4, beta5, beta6, beta7, beta8, beta9, beta10){
  # Probability (risk) of hypertension (needs 'expit' function from 'blm' package):
  p <-blm::expit(beta1+bmi1*beta2+bmi3*beta3+bmi4*beta4+cursmoke*beta5+age*beta6+female*beta7+educ2*beta8+educ3*beta9+educ4*beta10)
  # (beta - m) for penalty function:
  bm <-c(beta1, beta2, beta3, beta4, beta5, beta6, beta7, beta8, beta9, beta10)-m
  # The (penalized) -log likelihood:
  -(sum(dbinom(hyperten,1, p,log=TRUE))-bm%*%R%*%bm/2)
  }
# Define starting values:
beta0 <-list(beta1=0.5,beta2=0,beta3=0,beta4=0,beta5=0,beta6=0,beta7=0,beta8=0,beta9=0,beta10=0)
# Location parameter for penalty (log-odds ratio scale):
m <-rep(0,10)
m[2] <-log(1.5)# Prior location for beta2
m[3] <-log(1.1)# Prior location for beta3
m[4] <-log(2)# Prior location for beta4

# Precision parameter for penalty (log-odds ratio scale):
# (recall: precision = 1/variance)
R <-diag(0,10)
# Prior precision on beta2
R[2,2] <-2

# Prior precision on beta3
R[3,3] <-2

# Prior precision on beta4
R[4,4] <-2

## PRIOR 1##
logistic.fit.mle<-mle(nLL,start=beta0)
# OR and 95% CI:
prior1ORCI <- round(exp(cbind(coef(logistic.fit.mle),confint(logistic.fit.mle))),2)

##Unpenalized ##
R <-diag(0,10)
logistic.fit.mle.un<-mle(nLL,start=beta0)
# OR and 95% CI:
unORCI <- round(exp(cbind(coef(logistic.fit.mle.un),confint(logistic.fit.mle.un))),2)

```


```{r}
# Now we will adapt this code for prior 2:
attach(frmgham_recoded.wide)
hyperten <-hyperten
bmi1 <-as.integer(bmi_cat==1)
bmi2 <-as.integer(bmi_cat==2)
bmi3 <-as.integer(bmi_cat==3)
bmi4 <-as.integer(bmi_cat==4)

cursmoke <-cursmoke
age<-age
educ1 <-as.integer(educ==1)
educ2 <-as.integer(educ==2)
educ3 <-as.integer(educ==3)
educ4 <-as.integer(educ==4)

female <-as.integer(sex==2)
detach(frmgham_recoded.wide)

nLL <-function(beta1, beta2, beta3, beta4, beta5, beta6, beta7, beta8, beta9, beta10){
  # Probability (risk) of hypertension (needs 'expit' function from 'blm' package):
  p <-blm::expit(beta1+bmi1*beta2+bmi3*beta3+bmi4*beta4+cursmoke*beta5+age*beta6+female*beta7+educ2*beta8+educ3*beta9+educ4*beta10)
  # (beta - m) for penalty function:
  bm <-c(beta1, beta2, beta3, beta4, beta5, beta6, beta7, beta8, beta9, beta10)-m
  # The (penalized) -log likelihood:
  -(sum(dbinom(hyperten,1, p,log=TRUE))-bm%*%R%*%bm/2)
  }
# Define starting values:
beta0 <-list(beta1=0.5,beta2=0,beta3=0,beta4=0,beta5=0,beta6=0,beta7=0,beta8=0,beta9=0,beta10=0)
# Location parameter for penalty (log-odds ratio scale):
m <-rep(0,10)
m[2] <-log(1.5)# Prior location for beta2
m[3] <-log(1.1)# Prior location for beta3
m[4] <-log(2)# Prior location for beta4

## PRIOR 2 ##
# Precision parameter for penalty (log-odds ratio scale):
# (recall: precision = 1/variance)
R <-diag(0,10)
# Prior precision on beta2
R[2,2] <- ((2*1.96)/(log(3.997)-log(.563)))^2
# Prior precision on beta3
R[3,3] <- ((2*1.96)/(log(2.931)-log(.413)))^2
# Prior precision on beta4
R[4,4] <- ((2*1.96)/(log(5.329)-log(.751)))^2
# logistic fit for prior 2
logistic.fit.mle2<-mle(nLL,start=beta0)
# OR and 95% CI for prior 2:
prior2ORCI <- round(exp(cbind(coef(logistic.fit.mle2),confint(logistic.fit.mle2))),2)

## PRIOR 3 ##
# Precision parameter for penalty (log-odds ratio scale):
# (recall: precision = 1/variance)
R <-diag(0,10)
# Prior precision on beta2
R[2,2] <- ((2*1.96)/(log(2.788)-log(.808)))^2
# Prior precision on beta3
R[3,3] <- ((2*1.96)/(log(2.044)-log(.562)))^2
# Prior precision on beta4
R[4,4] <- ((2*1.96)/(log(3.72)-log(1.08)))^2
# logistic fit for prior 3
logistic.fit.mle3<-mle(nLL,start=beta0)
# OR and 95% CI for prior 3:
prior3ORCI <- round(exp(cbind(coef(logistic.fit.mle3),confint(logistic.fit.mle3))),2)
```

# Question 1: 
Using the notation for generalized linear models presented in class, write out the equations for each of the 3 models, in terms of the variables in the dataset. Clearly define all parameters in each of the models. (15 points)

## a. Logistic Regression Model:

Model:
\[
\begin{aligned}
logit(Pr(Y=1|X=x) = \beta_1 + (\beta_2*BMI_{underweight}) + (\beta_3*BMI_{overweight}) + (\beta_4*BMI_{obese}) + (\beta_5*curr smoke) + \\
(\beta_6*age) + (\beta_7*female) + (\beta_8*education_2) + (\beta_9*education_3) + (\beta_{10}*education_4)
\end{aligned}
\]

Equation: 

$logit(Pr(Y=1|X=x)$ = \texttt{`r coef.logistic[1]`} + 
(\texttt{`r coef.logistic[2]`} * $BMI_{underweight}$) +
(\texttt{`r coef.logistic[3]`} * $BMI_{overweight}$) +
(\texttt{`r coef.logistic[4]`} * $BMI_{obese}$) +
(\texttt{`r coef.logistic[5]`} * $currsmoke$) +
(\texttt{`r coef.logistic[6]`} * $age$) +
(\texttt{`r coef.logistic[7]`} * $female$) +
(\texttt{`r coef.logistic[8]`} * $education_2$) +
(\texttt{`r coef.logistic[9]`} * $education_3$) +
(\texttt{`r coef.logistic[10]`} * $education_4$) 

## b. Log-Binomial Model:

Model (Model would not converge despite providing starting values):
\[
\begin{aligned}
log(Pr(Y=1|X=x) = \beta_1 + (\beta_2*BMI_{underweight}) + (\beta_3*BMI_{overweight}) + (\beta_4*BMI_{obese}) + (\beta_5*curr smoke) + \\
(\beta_6*age) + (\beta_7*female) + (\beta_8*education_2) + (\beta_9*education_3) + (\beta_{10}*education_4)
\end{aligned}
\]

## c. "Modified Poisson" Model:

Equation: 

$log(Pr(Y=1|X=x)$ = \texttt{`r poissoncoef[1]`} + 
(\texttt{`r poissoncoef[2]`} * $BMI_{underweight}$) +
(\texttt{`r poissoncoef[3]`} * $BMI_{overweight}$) +
(\texttt{`r poissoncoef[4]`} * $BMI_{obese}$) +
(\texttt{`r poissoncoef[5]`} * $currsmoke$) +
(\texttt{`r poissoncoef[6]`} * $age$) +
(\texttt{`r poissoncoef[7]`} * $female$) +
(\texttt{`r poissoncoef[8]`} * $education_2$) +
(\texttt{`r poissoncoef[9]`} * $education_3$) +
(\texttt{`r poissoncoef[10]`} * $education_4$) 

\vspace{12pt}
\vspace{12pt}

# Question 2: 
For the logistic regression model write the log-likelihood function in general terms - variable names and parameters - no data values. (you may reference your answer to question 1(a) to make the notation concise). (10 points) 
\[
\mathcal{L}(\beta|y,x) = \sum_{i}log\left[\frac{exp(logit(Pr(Y=1|X=x_i))}{1+exp(logit(Pr(Y=1|X=x_i))})\right]^{y_i} \mathrm{x} \ \ \ log\left[1 - \frac{exp(logit(Pr(Y=1|X=x_i))}{1+exp(logit(Pr(Y=1|X=x_i))})\right]^{1-y_i}
\]

\vspace{12pt}
\vspace{12pt}

# Question 3:
Using the results from the models you estimated above, complete the following table. (15 points)

Table 2: Estimates of adjusted relative risk estimates of
the association between baseline BMI status and incident
hypertension. The Framingham Cohort Study. 1948-1972,
Framingham, MA.

BMI          | LogisticOR (95% CI) | Log-binomial RR (95% CI) | Poisson RR (95% CI)
------------ | ------------------- | ------------------------ | -------------------
< 18.5       | \texttt{`r LogisticORs[1,1]`} (\texttt{`r LogisticORs[1,2]`}, \texttt{`r LogisticORs[1,3]`}) | \ \ \ \ \ \ \ \ \ \ \ \ \ *Model*    | \texttt{`r PoissonRR[1,1]`} (\texttt{`r PoissonRR[1,2]`}, \texttt{`r PoissonRR[1,3]`})
18.5 - 29.4  | *ref*            | \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ *did*       | *ref*
25.0 - 29.9  | \texttt{`r LogisticORs[2,1]`} (\texttt{`r LogisticORs[2,2]`}, \texttt{`r LogisticORs[2,3]`})  | \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ *not*     | \texttt{`r PoissonRR[2,1]`} (\texttt{`r PoissonRR[2,2]`}, \texttt{`r PoissonRR[2,3]`})
$\ge$ 30     | \texttt{`r LogisticORs[3,1]`} (\texttt{`r LogisticORs[3,2]`}, \texttt{`r LogisticORs[3,3]`}) | \ \ \ \ \ \ \ \ \ \ \ *converge*  | \texttt{`r PoissonRR[3,1]`} (\texttt{`r PoissonRR[3,2]`}, \texttt{`r PoissonRR[3,3]`})

\vspace{12pt}
\vspace{12pt}

# Question 4:
Without considering any of the results, how well would you think the OR from the logistic model would approximate the RR from these data? When considering results from all of the models, which one do you think best characterizes the risk ratio? Why? (10 points)

*We would expect the OR will be further from the null than the RR, and since this outcome is not rare (incidence =* \texttt{`r round(hypertenprev[2],3)`}), *we would expect this overestimate to potentially be substantial.*

*We think the best model for characterizing the risk ratio is the "Modified Poisson" Model, since it allows for direct estimation of the RR using  log as the canonical link, and while statistical efficiency is compromised when using this model compared to log-binomial regression, it is more likely to successfully converge.*

\vspace{12pt}
\vspace{12pt}

# Question 5: 
Answer the following regarding the standardized measures of association: (15 points)

## a. 
Using results from the logistic model, what is the standardized risk ratio comparing the population where everyone is obese to the one where everyone is ideal weight? Explain how this is conceptually different than the corresponding measures of association in question 3.

*From the logistic model, the standardized risk ratio when comparing a counterfactual population where everyone is obese to one where everyone is ideal weight is* \texttt{`r round(Counterfactual.RR.logistic,3)`}. *This is conceptually different from the corresponding measures of association in question 3 because in this model we are standardizing conditional on the distribution of covariates that exist in our underlying population. In question 3, the model was conditional holding other covariates constant.* 

## b. 
Using results from the logistic model, what is the standardized risk difference comparing the population where everyone is obese to the one where everyone is ideal weight?

*From the logistic model, the standardized risk ratio when comparing a counterfactual population where everyone is obese to one where everyone is ideal weight is* \texttt{`r round(Counterfactual.RD.logistic,3)`}. 

## c. 
What are the risk ratio and risk difference from the modified Poisson model? Between the logistic and Poisson model, which one would you choose to report and why?

*From the "Modified Poisson" Model, the standardized risk ratio when comparing a counterfactual population where everyone is obese to one where everyone is ideal weight is* \texttt{`r round(Counterfactual.RR.poisson,3)`}. *The standardized risk difference is* \texttt{`r round(Counterfactual.RD.poisson,3)`}. *We would choose to report Poisson because Poisson is calculating relative risks directly, whereas in a logistic model we are approximating relative risks using an odds ratio, and particularly in the case of a common outcome such as hypertension, this is inadvisable.*

\vspace{12pt}
\vspace{12pt}

# Question 6: 
Answer the following questions about penalized likelihood estimation for a logistic regression model as above: (20 points)

## a. 
Write out a penalized log-likelihood function using a general expression for a quadratic penalty for the logistic regression model you defined in question 2. Clearly define all parameters, including those on the penalty function. (You may use either vector or summation notation.)
\[
\mathcal{L}_p(\beta|y,x) = \mathcal{L}(\beta|y,x) - (\beta - m)'R(\beta - m)/2
\]
*The penalized log-likelihood is equal to the usual log-likelihood (as defined in question 2), minus a quadratic penalty. The penalty is the inverse of the difference between the set of all beta coefficients and the vector m (means of the prior betas) multiplied by the tuning parameter (the prior precisions), again multiplied by the difference between beta and m, divided by two.*

## b. 
In one sentence, explain in words what the penalty function does in penalized maximum likelihood estimation.

*The penalty function adjusts your model to incorporate prior information, such that the likelihood values are increasingly decreased the further away they are from your prior betas.*

## c. 
Which parameters are being penalized in the above? Why?

*The likelihood of possible beta values, because you are calculating revised maximum likelihood that has been influenced by the prior information you have fed the model.*

## d. 
If the prior precision corresponding to each beta in this model is equal to 0 (an infinitely wide prior confidence interval), show how this implies that the penalized likelihood in 6 (a) is equivalent to the one in question 2, regardless of the value of m.
\[
\mathcal{L}_p(\beta|y,x) = \mathcal{L}(\beta|y,x) - (\beta - m)'0^*(\beta - m)/2 = \mathcal{L}(\beta|y,x)
\]

*As can be seen in the equation above, when the prior precision corresponding to each beta ($R$) is equal to zero, the penalty function drops to zero, leaving you with the usual log-likelihood.*

\vspace{12pt}
\vspace{12pt}

# Question 7. 
Using the results from the models you estimated above, complete the following table. What happens to the OR and confidence intervals as the prior precision increases? (15 points)

Table 3: Penalized maximum likelihood estimates of the
association between baseline BMI status and incident
hypertension under different parameterizations of a quadratic
penalty function. The Framingham Cohort Study. 1948-1972,
Framingham, MA.

BMI          | Unpenalized (Q2) | Scenario I: OR (95% CI) | Scenario II: OR (95% CI) | Scenario III: OR (95% CI)
------------ | ------------------- | ------------------ | ------------------- | ------------------
< 18.5       | \texttt{`r unORCI[2,1]`} (\texttt{`r unORCI[2,2]`}, \texttt{`r unORCI[2,3]`}) |  \texttt{`r prior1ORCI[2,1]`} (\texttt{`r prior1ORCI[2,2]`}, \texttt{`r prior1ORCI[2,3]`}) | \texttt{`r prior2ORCI[2,1]`} (\texttt{`r prior2ORCI[2,2]`}, \texttt{`r prior2ORCI[2,3]`}) |  \texttt{`r prior3ORCI[2,1]`} (\texttt{`r prior3ORCI[2,2]`}, \texttt{`r prior3ORCI[2,3]`}) 
18.5 - 29.4  | *ref*            | *ref*      | *ref*  | *ref*
25.0 - 29.9  | \texttt{`r unORCI[3,1]`} (\texttt{`r unORCI[3,2]`}, \texttt{`r unORCI[3,3]`})  |  \texttt{`r prior1ORCI[3,1]`} (\texttt{`r prior1ORCI[3,2]`}, \texttt{`r prior1ORCI[3,3]`}) |    \texttt{`r prior2ORCI[3,1]`} (\texttt{`r prior2ORCI[3,2]`}, \texttt{`r prior2ORCI[3,3]`}) |  \texttt{`r prior3ORCI[3,1]`} (\texttt{`r prior3ORCI[3,2]`}, \texttt{`r prior3ORCI[3,3]`}) 
$\ge$ 30     | \texttt{`r unORCI[4,1]`} (\texttt{`r unORCI[4,2]`}, \texttt{`r unORCI[4,3]`}) |   \texttt{`r prior1ORCI[4,1]`} (\texttt{`r prior1ORCI[4,2]`}, \texttt{`r prior1ORCI[4,3]`}) |  \texttt{`r prior2ORCI[4,1]`} (\texttt{`r prior2ORCI[4,2]`}, \texttt{`r prior2ORCI[4,3]`}) |  \texttt{`r prior3ORCI[4,1]`} (\texttt{`r prior3ORCI[4,2]`}, \texttt{`r prior3ORCI[4,3]`}) 

*As the prior precision increases, we expect the confidence intervals to decrease and the OR to be a better estimation of the true odds ratio.*